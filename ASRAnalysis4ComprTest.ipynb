{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do pidgins really exist? Do creoles come from pidgin?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This video features a lesson held by Prof. Michel DeGraff an Haitian Creolist. \n",
    "The speech is plain, not controlled and speaker has a strong accent.\n",
    "No noise.\n",
    "Google ASR system has been used for automatic captioning the video.\n",
    "Mistakes in the output will be used as a base to develop the comprehension test and to evaluate the systems performance in different conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I import all the modules I will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "import nbconvert\n",
    "import re\n",
    "import nltk\n",
    "import jiwer \n",
    "from jiwer import wer\n",
    "import nltk.corpus \n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "import collections\n",
    "import random\n",
    "import collections \n",
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When evaluating a ASR system it's important to keep in mind the nature of the speaker and the condition of the audio, therefore these measurements need to be interpreted accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word Error Rate (WER) is a comparison measure, it expresses the distance between the word sequence that produces an ASR and the reference series.\n",
    "\n",
    "WER = (S + D + I) / N1 = (S + D + I) / (H + S + D)\n",
    "\n",
    "where I = the total number of entries, D = total number of deletions, S = total number of replacements, H = total number of hits, and N1 = total number of reference words.\n",
    "\n",
    "Cons: it is not a real percentage, it has no upperbound (i.e. WER can be 200%). Used on its own it doesn't tell much about the system performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Match Error Rate (MER) is the proportion of I/O word matches, which are errors, which means that is the probability of a given match being incorrect.\n",
    "\n",
    "MER = (S + D + I) / (N = H + S + D + I) = 1 âˆ’ H/N"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word Information Lost (WIL) is a simple approximation to the proportion of word information lost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N reference:     8758\n",
      "N hypothesis:    8608\n",
      "\n",
      "wer              0.06647058823529411\n",
      "mer              0.06592765460910152\n",
      "wil              0.10091514960188008\n",
      "hits             1601\n",
      "substitutions    62\n",
      "deletions        37\n",
      "insertions       14\n"
     ]
    }
   ],
   "source": [
    "infile = open(\"Text files/Transcription.txt\", \"r\", encoding = \"utf8\")\n",
    "ref = infile.read().lower()\n",
    "infile.close()\n",
    "\n",
    "infile2 = open(\"Text files/auto_cc.txt\", \"r\", encoding = \"utf8\")\n",
    "hyp = infile2.read().lower()\n",
    "infile.close()\n",
    "\n",
    "reference = \" \".join(re.split(r\"\\W+\", ref))\n",
    "hypothesis = \" \".join(re.split(r\"\\W+\", hyp))\n",
    "\n",
    "measures = jiwer.compute_measures(reference, hypothesis)\n",
    "\n",
    "\n",
    "print(\"{0:15}  {1}\".format('N reference:', len(reference)))\n",
    "print(\"{0:15}  {1}\".format('N hypothesis:', len(hypothesis)))\n",
    "\n",
    "print( )\n",
    "\n",
    "for measure, val in measures.items():\n",
    "    if measure != 'wip':\n",
    "        print(\"{0:15}  {1}\".format(measure, val))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results are considered good and in line with Google ASR performance, which is the best one available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Line by line comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I created a text file containing both input and output texts. I will use the document to detect shift or change in meaning due to transcription errors of morphological or syntactic nature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell I have POS-tagged words and lemmatised the two texts and retrieved only the nouns and their frequencies to see how many keywords were transcribed correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input nouns:\n",
      "\n",
      "absence 2 |  affix 4 |  africa 1 |  african 3 |  anybody 1 |  anything 2 |  archival 1 |  argument 1 |  asia 1 |  attention 1 |  background 1 |  barrier 1 |  bell 1 |  bias 1 |  bickerton 3 |  business 1 |  candidate 1 |  child 6 |  china 1 |  choice 1 |  claim 5 |  coast 1 |  code 1 |  communication 1 |  community 5 |  complexity 1 |  concern 1 |  condition 1 |  creation 1 |  creole 12 |  data 9 |  debate 1 |  definition 2 |  difference 1 |  doubt 1 |  erectus 1 |  europe 1 |  evidence 6 |  example 2 |  fact 6 |  family 1 |  fifth 1 |  franca 1 |  french 1 |  generation 4 |  guess 1 |  hearing 1 |  history 2 |  home 1 |  homo 1 |  hypothesis 1 |  idea 2 |  kind 3 |  l'ouverture 1 |  language 18 |  latin 1 |  leader 1 |  level 1 |  line 1 |  marker 1 |  mean 1 |  nobody 2 |  observer 1 |  okay 3 |  order 1 |  part 1 |  patois 1 |  pattern 2 |  people 9 |  period 1 |  perspective 1 |  pidgin 21 |  piece 1 |  point 6 |  question 6 |  rachel 1 |  recording 4 |  remember 2 |  report 1 |  respond 1 |  revolution 1 |  right 3 |  scenario 1 |  sense 3 |  singer 1 |  situation 1 |  somebody 3 |  someone 2 |  something 2 |  sort 2 |  speaker 2 |  speech 2 |  stage 1 |  state 1 |  structure 4 |  switching 1 |  system 4 |  term 4 |  thing 2 |  time 1 |  toussaint 1 |  tunneling 1 |  type 1 |  unlanguage 1 |  variety 1 |  verb 1 |  version 1 |  well 1 |  whistle 1 |  word 2 |  yeah 4 |  \n",
      "\n",
      "Output nouns:\n",
      "\n",
      "absence 2 |  affix 4 |  africa 1 |  african 3 |  anybody 1 |  anything 2 |  archival 1 |  argument 1 |  asia 1 |  attention 1 |  background 1 |  barrier 1 |  bell 1 |  bias 1 |  bickerton 1 |  biggerton 1 |  bikerton 1 |  business 1 |  candidate 1 |  career 2 |  child 6 |  china 1 |  choice 1 |  claim 5 |  coast 1 |  code 1 |  community 5 |  complexity 1 |  condition 2 |  creation 1 |  creole 6 |  data 9 |  debate 1 |  definition 2 |  didn't 1 |  difference 1 |  doubt 1 |  erectus 1 |  europe 1 |  evidence 6 |  example 2 |  face 1 |  fact 5 |  family 1 |  fellow 1 |  franca 1 |  french 1 |  generation 4 |  girl 1 |  grill 1 |  hearing 1 |  history 2 |  home 1 |  hypothesis 1 |  idea 2 |  kind 3 |  language 18 |  leader 1 |  level 1 |  line 1 |  louis 1 |  market 1 |  mean 1 |  nobody 2 |  observer 1 |  okay 3 |  order 1 |  part 1 |  patois 1 |  pattern 2 |  people 8 |  period 1 |  pigeon 22 |  pitching 1 |  point 6 |  question 5 |  recording 4 |  remember 2 |  report 1 |  revolution 1 |  right 3 |  scenario 1 |  sense 3 |  show 1 |  singer 1 |  situation 1 |  somebody 3 |  someone 2 |  something 2 |  sort 1 |  speaker 2 |  speech 2 |  stage 1 |  state 1 |  story 1 |  structure 4 |  switching 1 |  system 4 |  term 4 |  thing 2 |  time 1 |  tunneling 1 |  type 1 |  unlanguage 1 |  variety 1 |  verb 1 |  version 1 |  well 1 |  whistle 1 |  word 2 |  yeah 4 |  "
     ]
    }
   ],
   "source": [
    "#TRANSCRIPTION\n",
    "\n",
    "infile = open(\"Text files/Transcription.txt\", \"r\", encoding = \"utf8\")\n",
    "ref = infile.read().lower()\n",
    "infile.close()\n",
    "\n",
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "\n",
    "is_noun = lambda pos: pos[:2] == 'NN'\n",
    "reference = [lemmatizer.lemmatize(word) for (word, pos) \n",
    "                                 in nltk.pos_tag(nltk.word_tokenize(ref)) if is_noun(pos)] \n",
    "count_ref = collections.Counter(reference)\n",
    "\n",
    "#AUTOMATIC CAPTIONS\n",
    "\n",
    "infile = open(\"Text files/auto_cc.txt\", \"r\", encoding = \"utf8\")\n",
    "hyp = infile.read().lower()\n",
    "infile.close()\n",
    "\n",
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "\n",
    "is_noun = lambda pos: pos[:2] == 'NN'\n",
    "\n",
    "hypothesis = [lemmatizer.lemmatize(word) for (word, pos) \n",
    "              in nltk.pos_tag(nltk.word_tokenize(hyp)) if is_noun(pos)]\n",
    "\n",
    "count_hyp = collections.Counter(hypothesis)\n",
    "\n",
    "#LET'S PRINT BOTH\n",
    "print(\"Input nouns:\\n\")\n",
    "\n",
    "for word, val in sorted(count_ref.items()): \n",
    "    if len(word) > 3:\n",
    "        print(\"{} {} {} \".format(word, val,  \"|\"), end = \" \")\n",
    "\n",
    "print(\"\\n\") \n",
    "  \n",
    "print('Output nouns:\\n')\n",
    "\n",
    "for word, val in sorted(count_hyp.items()): \n",
    "    if len(word) > 3:\n",
    "        print(\"{} {} {} \".format(word, val,  \"|\"), end = \" \")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By cross-referring nouns frequency data and the texts alignment we can see that original keywords have been transcribe as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic keywords:\n",
      "\n",
      "affix 4 |  bickerton 3 |  creole 12 |  pidgin 21 |  structure 4 |  \n",
      "\n",
      "\n",
      "Output:\n",
      "\n",
      "affix 4     = affix 4\n",
      "\n",
      "bickerton 4 = bickerton 1 + biggerton 1 + bikerton 1 + because 1\n",
      "\n",
      "creole 12   = creole 6 + career 2 + girl 1 + grill 1 + critical 1 + curl 1\n",
      "\n",
      "pidgin 21   = pigeon 22 + pitching 1\n",
      "\n",
      "structure 4 = structure 4\n"
     ]
    }
   ],
   "source": [
    "print(\"Topic keywords:\\n\")\n",
    "      \n",
    "for word, val in sorted(count_ref.items()): \n",
    "    if word in [\"pidgin\", \"creole\", \"affix\", \"bickerton\", \"structure\"]:\n",
    "        print(\"{} {} {} \".format(word, val,  \"|\"), end = \" \")\n",
    "        \n",
    "print(\"\\n\\n\")   \n",
    "\n",
    "print(\"Output:\\n\")\n",
    "print(\"{0:11} {1} {2}\".format(\"affix 4 \", \"=\" , \"affix 4\"))\n",
    "print(\"{0:10} {1}\".format(\"\\nbickerton 4 =\", \"bickerton 1 + biggerton 1 + bikerton 1 + because 1\"))\n",
    "print(\"{0:12} {1} {2}\".format(\"\\ncreole 12\", \"=\", \"creole 6 + career 2 + girl 1 + grill 1 + critical 1 + curl 1\"))\n",
    "print(\"{0:12} {1} {2}\".format(\"\\npidgin 21\", \"=\", \"pigeon 22 + pitching 1\"))\n",
    "print(\"{0:12} {1} {2}\".format(\"\\nstructure 4\", \"=\", \"structure 4\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following errors - caused mainly by co-articulation - are problematic because they make perfect sense from a linguistic point of view but the meaning has changed from the original sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(an original speech system) that's extremely\u001b[94m'rich using structure'\u001b[0m\n",
      "(an original speech system) that's extremely '\u001b[94m'reducing structure''\u001b[0m\n",
      "\n",
      "\n",
      "They are really simplest \u001b[94mimpossible'\u001b[0m system -- in fact, even un-language-like \n",
      "they're really simply system \u001b[94mpossible'\u001b[0m in fact even uh unlanguage like\n",
      "\n",
      "\n",
      "there was a system where all the French \u001b[94msuffixes\u001b[0m were gone\n",
      "there was a system where all the french \u001b[94maffixes\u001b[0m were gone\n",
      "\n",
      "\n",
      "In the cases above the human made caption is wrong and the automatic one is correct\n",
      "\n",
      "\n",
      "so in the history of \u001b[94mHaitian Creole\u001b[0m\n",
      "so in the history of \u001b[94masian creole'\u001b[0m\n",
      "\n",
      "\n",
      "if there is a recording, we're like, OK, oh, \u001b[94mthen a pidgin did exist\u001b[0m.\n",
      "if there is a recording we're like okay oh then \u001b[94mthen it didn't exist\u001b[0m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"(an original speech system) that's extremely\\033[94m'rich using structure'\\033[0m\\n(an original speech system) that's extremely '\\033[94m'reducing structure''\\033[0m\")\n",
    "print(\"\\n\")\n",
    "print(\"They are really simplest \\033[94mimpossible'\\033[0m system -- in fact, even un-language-like \\nthey're really simply system \\033[94mpossible'\\033[0m in fact even uh unlanguage like\")\n",
    "print(\"\\n\")\n",
    "print(\"there was a system where all the French \\033[94msuffixes\\033[0m were gone\")\n",
    "print(\"there was a system where all the french \\033[94maffixes\\033[0m were gone\")\n",
    "print(\"\\n\")\n",
    "print(\"In the cases above the human made caption is wrong and the automatic one is correct\")\n",
    "print(\"\\n\")\n",
    "print(\"so in the history of \\033[94mHaitian Creole\\033[0m\")\n",
    "print(\"so in the history of \\033[94masian creole'\\033[0m\")\n",
    "print(\"\\n\")\n",
    "print(\"if there is a recording, we're like, OK, oh, \\033[94mthen a pidgin did exist\\033[0m.\")\n",
    "print(\"if there is a recording we're like okay oh then \\033[94mthen it didn't exist\\033[0m\")\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, the following sentences are almost nonsensical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you might go to a stage where you \u001b[94mproduce Italian verbs without affixes\u001b[0m\n",
      "you might go through a state where you \u001b[94mput your satanic verbs without affixes\u001b[0m\n",
      "\n",
      "\n",
      "so in terms of just a mix, you see-- so \u001b[94min Haitian creole revolution\u001b[0m\n",
      "so in terms of just the mix you see so \u001b[94minhibition critical revolution\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(\"you might go to a stage where you \\033[94mproduce Italian verbs without affixes\\033[0m\")\n",
    "print(\"you might go through a state where you \\033[94mput your satanic verbs without affixes\\033[0m\")\n",
    "print(\"\\n\")\n",
    "print(\"so in terms of just a mix, you see-- so \\033[94min Haitian creole revolution\\033[0m\")\n",
    "print(\"so in terms of just the mix you see so \\033[94minhibition critical revolution\\033[0m\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Proper nouns became:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bickerton:\n",
      "\n",
      "\u001b[94mBickerton has used\u001b[0m something of that kind of argument\n",
      "\u001b[94mbecause use\u001b[0m something of that that kind of argument\n",
      "\n",
      "\n",
      "there was anything like what \u001b[94mBickerton\u001b[0m posits\n",
      "there was anything like what \u001b[94mbiggerton\u001b[0m posits\n",
      "\n",
      "\n",
      "remember that for \u001b[94mBickerton\u001b[0m, the \u001b[94mcrucial fifth piece\u001b[0m (of his theory) is\n",
      "remember for \u001b[94mbikerton\u001b[0m you know the \u001b[94mcrucial face\u001b[0m is\n",
      "\n",
      "\n",
      "\n",
      "Toussaint L'Ouverture:\n",
      "\n",
      "\n",
      "So someone like \u001b[94mToussaint L'Ouverture\u001b[0m, for example, the well-known Haitian leader\n",
      "so someone like \u001b[94mlouis veracio\u001b[0m for example you know the well-known haitian leader\n"
     ]
    }
   ],
   "source": [
    "print(\"Bickerton:\\n\")\n",
    "print(\"\\033[94mBickerton has used\\033[0m something of that kind of argument\")\n",
    "print(\"\\033[94mbecause use\\033[0m something of that that kind of argument\")\n",
    "print(\"\\n\")\n",
    "print(\"there was anything like what \\033[94mBickerton\\033[0m posits\")\n",
    "print(\"there was anything like what \\033[94mbiggerton\\033[0m posits\")\n",
    "print(\"\\n\")\n",
    "print(\"remember that for \\033[94mBickerton\\033[0m, the \\033[94mcrucial fifth piece\\033[0m (of his theory) is\")\n",
    "print(\"remember for \\033[94mbikerton\\033[0m you know the \\033[94mcrucial face\\033[0m is\")\n",
    "print(\"\\n\\n\")\n",
    "print(\"Toussaint L'Ouverture:\")\n",
    "print(\"\\n\")\n",
    "print(\"So someone like \\033[94mToussaint L'Ouverture\\033[0m, for example, the well-known Haitian leader\")\n",
    "print(\"so someone like \\033[94mlouis veracio\\033[0m for example you know the well-known haitian leader\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One sentence sounds better, though:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you're already creating a bias against the area that--\n",
      "you're already increasing your bias against the idea that\n",
      "\n",
      "\n",
      "(African people were learning French like French people were learning Latin in the past)\n"
     ]
    }
   ],
   "source": [
    "print(\"you're already creating a bias against the area that--\")\n",
    "print(\"you're already increasing your bias against the idea that\")\n",
    "print(\"\\n\")\n",
    "print(\"(African people were learning French like French people were learning Latin in the past)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B, F. F. (2020). A Benchmarking of IBM , Google and Wit. Springer International Publishing. https://doi.org/10.1007/978-3-030-49161-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MIT Opencourseware 24.908, Spring 2017\n",
    "Creole Languages and Carribean Identities - Michel DeGraff\n",
    "Lesson 1. Do \"Pidgins\" exist? Do creoles come from pidgin?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Morris, A. C., Maier, V., & Green, P. (2004). From WER and RIL to MER and WIL: Improved evaluation measures for connected speech recognition. 8th International Conference on Spoken Language Processing, ICSLP 2004, June, 2765â€“2768."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
